{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers= 4\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root='Datasets',\n",
    "                                    train = True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='Datasets',\n",
    "                                    train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size,shuffle=True,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 3.])\n",
      "tensor([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 784\n",
    "num_hiddens = 256\n",
    "num_outputs = 10\n",
    "\n",
    "#def init_params():  #3.12看到的\n",
    "#    w = torch.randn((num_inputs, 1), requires_grad=True)\n",
    "#    b = torch.zeros(1, requires_grad=True)\n",
    "#    return [w, b]\n",
    "\n",
    "#W1 = torch.randn(num_inputs,num_hiddens)\n",
    "W1 = torch.Tensor(np.random.normal(0,0.01,(num_inputs,num_hiddens)))\n",
    "b1 = torch.zeros(num_hiddens)\n",
    "#W2 = torch.randn(num_hiddens,num_outputs)\n",
    "W2 = torch.Tensor(np.random.normal(0,0.01,(num_hiddens,num_outputs)))\n",
    "b2 = torch.zeros(num_outputs)\n",
    "params =[W1,b1,W2,b2]\n",
    "for param in params:\n",
    "    param.requires_grad_(requires_grad=True)  #param!!!\n",
    "\n",
    "def softmax(y):\n",
    "    y_exp = y.exp()\n",
    "    return y_exp/y_exp.sum(dim=1,keepdim=True)\n",
    "    \n",
    "def relu(X):\n",
    "    return torch.max(X,torch.tensor(0.0))\n",
    "test1 = torch.Tensor([-1,2,3])\n",
    "print(relu(test1))\n",
    "def net(X):\n",
    "    hidden = relu(torch.mm(X.view(-1,num_inputs),W1)+b1)\n",
    "    return torch.mm(hidden,W2)+b2  #这里为什么不能加softmax???!!!加入softmax两种loss函数都得不到什么结果\n",
    "\n",
    "def cross_entropy_loss(y_hat,y):\n",
    "    return -torch.log(y_hat.gather(1,y.view(-1,1)))\n",
    "\n",
    "loss_data = torch.tensor([[1.0,2.0,3],[4,5,6]])\n",
    "indices = torch.LongTensor([1,2])\n",
    "#print(cross_entropy_loss(loss_data,indices))\n",
    "    \n",
    "def accuracy(y_hat,y):\n",
    "    return  (y_hat.argmax(dim=1)==y).float().sum().item()  #这里写成mean()导致问题。\n",
    "def accuracy_data_iter(data_iter):\n",
    "    acc_sum,n=0.0,0\n",
    "    for X,y in data_iter:\n",
    "        y_hat = net(X)\n",
    "        acc_sum += accuracy(y_hat,y)\n",
    "        n += y.shape[0]\n",
    "    return acc_sum/n\n",
    "\n",
    "def sgd(params,lr,batch_size):  #更新的时候为什么 除以256？？？\n",
    "    for param in params:\n",
    "        param.data-=param.grad*lr/batch_size\n",
    "\n",
    "    \n",
    "def test(x):\n",
    "    x.data=x+1   #x=x+1,就不会改变\n",
    "y = torch.tensor([1,2,3])\n",
    "test(y)\n",
    "print(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1, loss = 0.003, train accuray = 0.711, test accracy = 0.787\n",
      "epoch= 2, loss = 0.002, train accuray = 0.822, test accracy = 0.739\n",
      "epoch= 3, loss = 0.002, train accuray = 0.844, test accracy = 0.815\n",
      "epoch= 4, loss = 0.002, train accuray = 0.855, test accracy = 0.839\n",
      "epoch= 5, loss = 0.001, train accuray = 0.866, test accracy = 0.835\n",
      "epoch= 6, loss = 0.001, train accuray = 0.869, test accracy = 0.841\n",
      "epoch= 7, loss = 0.001, train accuray = 0.877, test accracy = 0.846\n",
      "epoch= 8, loss = 0.001, train accuray = 0.879, test accracy = 0.856\n",
      "epoch= 9, loss = 0.001, train accuray = 0.883, test accracy = 0.862\n",
      "epoch= 10, loss = 0.001, train accuray = 0.887, test accracy = 0.864\n"
     ]
    }
   ],
   "source": [
    "epochs =10\n",
    "lr = 100  #自己写的loss 10000才能勉强能从0.1到0.17\n",
    "#loss = cross_entropy_loss  #自己写的已经很难训练了\n",
    "loss = torch.nn.CrossEntropyLoss() #相同情况下，这个loss在随机初始化时很快能寻到0.84+\n",
    "#在上面参数训的很差的情况下也能很快从0.1训练到0.7+\n",
    "params =[W1,b1,W2,b2]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_sum,acc_sum,n=0.0,0.0,0\n",
    "    for X,y in train_iter:\n",
    "        #print(X.size())\n",
    "        y_hat = net(X)\n",
    "        #print((y_hat==0).sum())   #没有0元素\n",
    "        #test = loss(y_hat,y)\n",
    "        #print((test==0).sum())\n",
    "        l = loss(y_hat,y).sum()\n",
    "        l.backward()\n",
    "        sgd(params,lr,batch_size)\n",
    "        for param in params:\n",
    "            param.grad.data.zero_()\n",
    "        loss_sum +=l\n",
    "        acc_sum +=accuracy(y_hat,y)\n",
    "        n += y.shape[0]\n",
    "    test_acc = accuracy_data_iter(test_iter)\n",
    "    print('epoch= %d, loss = %.3f, train accuray = %.3f, test accracy = %.3f'%\n",
    "         (epoch+1,loss_sum/n,acc_sum/n,test_acc))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
